{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniprojekt zur Textklassifikation mit Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 1: Theorie\n",
    "Lesen Sie [Sebastian Raschkas Artikel](http://sebastianraschka.com/Articles/2014_naive_bayes_1.html) über das Naive Bayes Verfahren und beantworten Sie folgende Fragen:\n",
    "1. Weshalb ist *zusätzliche Glättung* hilfreich? Wie nennt sich dieses Verfahren in unserem Theorieteil?\n",
    "2. Was versteht man unter dem Begriff *Stop Word*?\n",
    "3. Warum eignet sich das *Multi-variate Bernoulli Naive Bayes Verfahren* für die Spam-Erkennung?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Weshalb ist *zusätzliche Glättung* hilfreich?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausprägungen unserer Features, die im Trainingsdatensatz nicht vorkommen, führen dazu, dass die **klassenbedingte Wahrscheinlichkeit** hierfür bei 0 liegt. Dies hat zur Folge, dass auch die a-posteriori Wahrscheinlichkeit hierfür stets bei 0 liegen wird. Um dieses Problem zu umgehen, wird ein zusätzlicher Parameter $\\alpha$ im Bayes-Modell addiert. Dies nennt man häufig auch *Lidstone*-Glättung oder *Laplace*-Glättung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Was versteht man unter dem Begriff *Stop Word*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein \"Stop Word\" ist ein Wort, welches für Erkennung des Textinhaltes/Klassifikation keinen Informationsgewinn bedeutet (sie widersprechen damit den Kriterien der **Auffälligkeit** (engl. *salience*) und der **Unterscheidungsfähigkeit** (engl. *discrimination*).\n",
    "\n",
    "Typischerweise sind dies Artikel, Konjunktionen etc. Möglichkeiten zum Ausfiltern dieser Wörter vor der Modellbildung sind der Abgleich gegen ein \"Stop-Word\" Wörterbuch der betrachteten Sprache(n). Möglich ist auch aus den Testdaten eine geordnete Liste mit den Häufigkeiten der verwendeten Wörter zu erstellen. Hieraus kann man nun händisch eine Liste mit Stop-Words erstellen und diese aus den Testdaten herausnehmen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Warum eignet sich das *Multi-variate Bernoulli Naive Bayes Verfahren* für die Spam-Erkennung?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für eine allgemeine Textklassifikation ist das Multi-variate-Bernoulli Naive Bayes Verfahren theoretisch dem Multinomialen Modell unterlegen, da hier die Häufigkeit eines Feautures nicht berücksichtigt wird, sondern nur, ob es überhaupt vorkommt oder nicht. Allerdings ist für die Güte eines Modells für die Spamerkennung vielmehr die Auswahl des Vokabulars (Herausnehmen von Stop-Words etc.) entscheidend. Es kommt hier also ganz entscheidend auf eine gute *Data Preparation* an!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 2: KDD-Prozess und CRISP-DM\n",
    "Recherchieren Sie, was es mit dem KDD-Prozess auf sich hat. Welchen Zusammenhang mit dem CRISP-DM bzw. welche Unterschiede zum CRISP-DM sehen Sie? Versuchen Sie die Schritte zur Lösung der *Data Mining Aufgabe* bestehend aus den Teilen 3 und 4 unten den Phasen des KDD-Prozesses zuzuordnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 3: Modellerstellung für Sentiment-Analyse\n",
    "Führen Sie mit dem Datensatz `../data/amazon_cells_labelled.txt` des Papers [From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences) eine Sentiment-Analyse durch. Es soll ein Modell generiert werden, mit dessen Hilfe eine Bewertung auf Amazon als *positiv* oder *negativ* eingestuft werden kann. \n",
    "\n",
    "Weitere Informationen zur Sentiment-Analyse und NLP-Verfahren im Allgemeinen finden Sie in Kapitel 8 des Buches [Python Machine Learning](https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning) von [Sebastian Raschka](https://sebastianraschka.com/blog/index.html). Dort wird zwar kein Naive Bayes-Modell verwendet, die Schritte Data Understanding und Data Preparation laufen aber sehr ähnlich ab.\n",
    "\n",
    "#### Hinweis\n",
    "* Lesen Sie die Daten korrekt als *pandas Dataframe* ein und vergeben Sie sinnvolle Namen für die Spalten.\n",
    "* Überprüfen Sie die Balance der Daten. Wieviele Bewertungen sind positiv, wieviele negativ? Können Sie sicher stellen, dass diese Balance auch in den Trainings- und Testdaten die gleiche ist (hierzu ist der Begriff \"stratification\" hilfreich ...)?\n",
    "* Bewerten Sie das Ergebnis immer mit Bezug auf die Null-Accuracy. Das ist die Genauigkeit, die ein Modell erzielt, welches stupide die häufigste Merkmalsausprägung annimmt. Ist ihr Modell besser oder schlechter als die Null-Accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import der Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Label\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daten sind durch Tab getrennt und haben keinen header.\n",
    "df_ama = pd.read_csv('../data/amazon_cells_labelled.txt', sep='\\t', header=None, names=['Comment', 'Label'])\n",
    "df_ama.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Überprüfen der Balance der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Comment\n",
       "Label         \n",
       "0          500\n",
       "1          500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ama.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es liegt also ein perfekt ausbalancierter Datensatz vor. Das ist in der Realität selten der Fall..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellung der Merkmalsmatrix und des Label-Vektors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1847)\n"
     ]
    }
   ],
   "source": [
    "# Tfidf-Vektorisierer mit den default-Einstellungen wird angewendet. \n",
    "tf = text.TfidfVectorizer()\n",
    "X_vec_ama = tf.fit(df_ama['Comment'])\n",
    "X_ama = X_vec_ama.transform(df_ama['Comment'])\n",
    "print(X_ama.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Merkmalsmatrix hat ~0.49% von Null verschiedene Einträge.\n"
     ]
    }
   ],
   "source": [
    "print(\"Die Merkmalsmatrix hat ~{0:.2f}% von Null verschiedene Einträge.\".format(\n",
    "          100 * X_ama.nnz / float(X_ama.shape[0] * X_ama.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen des Label-Vektors\n",
    "y_ama = df_ama['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufteilung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilung der Daten in Trainings- und Testdaten\n",
    "(X_train, X_test, y_train, y_test) = ms.train_test_split(\n",
    "    X_ama, y_ama, test_size=.2, random_state = 17, stratify=y_ama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Einfache Überprüfung der Stratifikation\n",
    "Erstmal für die Trainingsdaten ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es gibt 800 Trainingsdaten, davon 400 positive\n"
     ]
    }
   ],
   "source": [
    "print('Es gibt {} Trainingsdaten, davon {} positive'.format(y_train.count(), y_train.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... und zur Sicherheit auch noch für die Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es gibt 200 Testdaten, davon 100 positive\n"
     ]
    }
   ],
   "source": [
    "print('Es gibt {} Testdaten, davon {} positive'.format(y_test.count(), y_test.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training des Bernoulli\n",
    "bnb = ms.GridSearchCV(nb.MultinomialNB(), param_grid={'alpha':np.logspace(-2., 2., 50)}, cv=5)\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist +31,5% besser als die Null-Accuracy. Bedenkt man die erhöhte Komplexität der Aufgabe und die Einfachheit des NB-Algorithmus ist das Ergebnis nicht zu verachten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teil 4: Anwendung des Modells: Bewertungen anderer Plattformen\n",
    "Testen Sie ihr Amazon-Modell anhand der Bewertungen bei IMDB und Yelp. Diese finden Sie im gleichen Ordner unter `imdb_labelled.txt` und `yelp_labelled.txt`. Inwiefern ist das Amazon-Modell für die anderen Datensätze brauchbar?\n",
    "\n",
    "#### Hinweis\n",
    "* Damit die Übertragung des Modells gelingt, muss die Merkmalsmatrix der neuen Daten die gleiche Struktur aufweisen. Das trainierte Modell kann schließlich keine Wörter bewerten, die es nicht kennt!\n",
    "* Achten Sie erneut auf die Balance der Daten. Stichwort: Null-Accuracy!\n",
    "* Um die Güte eines Modells zu bestimmen, kann es sinnvoll sein, eine Confusion-Matrix aufzustellen. In Scikit-learn ist diese im Paket [metrics](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) zu finden. Eine schöne Option zum Plot ist in [mlxtend](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/) enthalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Test mit IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Label\n",
       "0  A very, very, very slow-moving, aimless movie ...      0\n",
       "1  Not sure who was more lost - the flat characte...      0\n",
       "2  Attempting artiness with black & white and cle...      0\n",
       "3       Very little music or anything to speak of.        0\n",
       "4  The best scene in the movie was when Gerardo i...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb =  pd.read_csv('../data/imdb_labelled.txt', sep='\\t', \n",
    "                       header=None, names=['Comment', 'Label'])\n",
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Überprüfen der Balance der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Comment\n",
       "Label         \n",
       "0          362\n",
       "1          386"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier ist der Datensatz ausbalanciert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun folgt die Transformation in die Amazon-Merkmalsmatrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imdb = X_vec_ama.transform(df_imdb['Comment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis**: Bei diesem Schritt gehen Wörter verloren, die zwar im IMDB-Datensatz enthalten sind, aber nicht im Amazon-Datensatz vorkommen. Es findet also ein Verlust von Informationen statt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_imdb = df_imdb['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Genauigkeit beträgt ~66.71% .\n"
     ]
    }
   ],
   "source": [
    "print(\"Die Genauigkeit beträgt ~{0:.2f}% .\".format(100*bnb.score(X_imdb, y_imdb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und zum Vergleich nun die Null-Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Null-Accuracy ist das Verhältnis der positiven Bewertungen zu allen\n"
     ]
    }
   ],
   "source": [
    "imdb_nmb = y_imdb.count()\n",
    "imdb_nmbpos = np.count_nonzero(y_imdb)\n",
    "imdb_nmbneg = imdb_nmb - imdb_nmbpos\n",
    "if imdb_nmbpos >= imdb_nmbneg:\n",
    "    print('Die Null-Accuracy ist das Verhältnis der positiven Bewertungen zu allen')\n",
    "else:\n",
    "    print('Die Null-Accuracy ist das Verhältnis der negativen Bewertungen zu allen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Null-Accuracy beträgt ~51.60% .\n"
     ]
    }
   ],
   "source": [
    "imdb_nacc = 100*imdb_nmbpos/imdb_nmb\n",
    "print(\"Die Null-Accuracy beträgt ~{0:.2f}% .\".format(imdb_nacc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis fällt deutlich schlechter aus, liegt aber noch signifikant über der Null-Accuracy. Dies lässt darauf schließen, dass der Textkorpus der beiden Datensätze sich immerhin zu einem gewissen Teil deckt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test mit Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einlesen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We'll never go again.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He also came back to check on us regularly, ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This place is pretty good, nice little vibe in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Join the club and get awesome offers via email.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Label\n",
       "0                              We'll never go again.      0\n",
       "1  He also came back to check on us regularly, ex...      1\n",
       "2                                 I love this place.      1\n",
       "3  This place is pretty good, nice little vibe in...      1\n",
       "4    Join the club and get awesome offers via email.      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp =  pd.read_csv('../data/yelp_labelled.txt', sep='\\t', \n",
    "                       header=None, names=['Comment', 'Label'])\n",
    "df_yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Überprüfen der Balance der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Comment\n",
       "Label         \n",
       "0          100\n",
       "1          500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine positive Bewertung ist in diesem Datensatz also 5 mal so häufig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird anschließend erneut in die Amazon-Merkmalsmatrix transformiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_yelp = X_vec_ama.transform(df_yelp['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_yelp = df_yelp['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Genauigkeit beträgt ~68.67% .\n"
     ]
    }
   ],
   "source": [
    "print(\"Die Genauigkeit beträgt ~{0:.2f}% .\".format(100*bnb.score(X_yelp, y_yelp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis liegt in einer ähnlichen Größenordnung wie bei den IMDB-Daten. Da die Yelp-Daten aber nicht ausbalanciert sind, ist es durchaus sinnvoll, eine Confusion-Matrix aufzustellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 79,  21],\n",
       "       [167, 333]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_yelp, bnb.predict(X_yelp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das kann man mit `mlxtend` übersichtlicher plotten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_yelp, bnb.predict(X_yelp)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "138 positive Bewertungen wurden als negativ klassifiziert (False-Positives oder Fehler 1. Art bei Nullhypothese: *Eine Bewertung ist positiv*) und 31 negative Bewertungen wurden als positiv klassifiziert (False-Negatives oder Fehler 2. Art). Das Modell begeht also ~4 mal so häufig einen Fehler 1. Art. Es liegt also ein Bias zugunsten einer negativen Bewertung vor. Dies ist nicht weiter verwunderlich, da das Modell an einem ausbalancierten Datensatz trainiert wurde. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Null-Accuracy ist das Verhältnis der positiven Bewertungen zu allen\n"
     ]
    }
   ],
   "source": [
    "yelp_nmb = y_yelp.count()\n",
    "yelp_nmbpos = np.count_nonzero(y_yelp)\n",
    "yelp_nmbneg = yelp_nmb - yelp_nmbpos\n",
    "if yelp_nmbpos >= yelp_nmbneg:\n",
    "    print('Die Null-Accuracy ist das Verhältnis der positiven Bewertungen zu allen')\n",
    "else:\n",
    "    print('Die Null-Accuracy ist das Verhältnis der negativen Bewertungen zu allen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Genauigkeit würde also ein \"dummes\" Modell erzielen, welches immer nur ein positives Sentiment annimmt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Null-Accuracy beträgt ~83.33% .\n"
     ]
    }
   ],
   "source": [
    "yelp_nacc = 100*yelp_nmbpos/yelp_nmb\n",
    "print(\"Die Null-Accuracy beträgt ~{0:.2f}% .\".format(yelp_nacc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das so erzielte Ergebnis ist also besser als das trainierte Modell! Wenn ein Modell diese Null-Accuracy nicht übertrifft, kann es eigentlich verworfen werden..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
